{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from smplx import SMPLX\n",
    "from mocap_dataset_process.utils.face_z_align_util import joint_idx, face_z_transform\n",
    "from mocap_dataset_process.utils.rotation_conversions import *\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_canonical_transform(global_orient):\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, -1, 0]\n",
    "    ], dtype=global_orient.dtype)\n",
    "    global_orient_matrix = axis_angle_to_matrix(global_orient)\n",
    "    global_orient_matrix = torch.matmul(rotation_matrix, global_orient_matrix)\n",
    "    global_orient = matrix_to_axis_angle(global_orient_matrix)\n",
    "    return global_orient\n",
    "\n",
    "def transform_translation(trans):\n",
    "    trans_matrix = np.array([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]])\n",
    "    trans = np.dot(trans, trans_matrix)  # exchange the y and z axis\n",
    "    trans[:, 2] = trans[:, 2] * (-1)\n",
    "    return trans\n",
    "\n",
    "\n",
    "def get_smplx_322(data, ex_fps):\n",
    "    fps = 0\n",
    "\n",
    "\n",
    "    if 'mocap_frame_rate' in data:\n",
    "        fps = data['mocap_frame_rate']\n",
    "        print(fps)\n",
    "        down_sample = int(fps / ex_fps)\n",
    "        \n",
    "    elif 'mocap_framerate' in data:\n",
    "        fps = data['mocap_framerate']\n",
    "        print(fps)\n",
    "        down_sample = int(fps / ex_fps)\n",
    "    else:\n",
    "        # down_sample = 1\n",
    "        return None\n",
    "\n",
    "    frame_number = data['trans'].shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    fId = 0 # frame id of the mocap sequence\n",
    "    pose_seq = []\n",
    "\n",
    "    \n",
    "\n",
    "    for fId in range(0, frame_number, down_sample):\n",
    "        pose_root = data['root_orient'][fId:fId+1]\n",
    "        pose_body = data['pose_body'][fId:fId+1]\n",
    "        pose_hand = data['pose_hand'][fId:fId+1]\n",
    "        pose_jaw = data['pose_jaw'][fId:fId+1]\n",
    "        pose_expression = np.zeros((1, 50))\n",
    "        pose_face_shape = np.zeros((1, 100))\n",
    "        pose_trans = data['trans'][fId:fId+1]\n",
    "        pose_body_shape = data['betas'][:10][None, :]\n",
    "        pose = np.concatenate((pose_root, pose_body, pose_hand, pose_jaw, pose_expression, pose_face_shape, pose_trans, pose_body_shape), axis=1)\n",
    "        pose_seq.append(pose)\n",
    "\n",
    "    pose_seq = np.concatenate(pose_seq, axis=0)\n",
    "    \n",
    "\n",
    "    return pose_seq\n",
    "\n",
    "def process_pose(pose):\n",
    "    pose_root = pose[:, :3]\n",
    "    pose_root = compute_canonical_transform(torch.from_numpy(pose_root)).detach().cpu().numpy()\n",
    "    pose[:, :3] = pose_root\n",
    "    pose_trans = pose[:, 309:312]\n",
    "    pose_trans = transform_translation(pose_trans)\n",
    "    pose[:, 309:312] = pose_trans\n",
    "\n",
    "    return pose\n",
    "\n",
    "\n",
    "def face_z_align(pose, smplx_model):\n",
    "    pose = torch.from_numpy(pose).float().cuda()\n",
    "\n",
    "    param = {\n",
    "        'root_orient': pose[:, :3],  # controls the global root orientation\n",
    "        'pose_body': pose[:, 3:3+63],  # controls the body\n",
    "        'pose_hand': pose[:, 66:66+90],  # controls the finger articulation\n",
    "        'pose_jaw': pose[:, 66+90:66+93],  # controls the yaw pose\n",
    "        'face_expr': pose[:, 159:159+50],  # controls the face expression\n",
    "        'face_shape': pose[:, 209:209+100],  # controls the face shape\n",
    "        'trans': pose[:, 309:309+3],  # controls the global body position\n",
    "        'betas': pose[:, 312:],  # controls the body shape. Body shape is static\n",
    "    }\n",
    "\n",
    "    batch_size = param['face_expr'].shape[0]\n",
    "    zero_pose = torch.zeros((batch_size, 3)).float().cuda()\n",
    "\n",
    "    smplx_output = smplx_model(betas=param['betas'], body_pose=param['pose_body'],\n",
    "                               global_orient=param['root_orient'], pose2rot=True, jaw_pose=zero_pose, leye_pose=zero_pose, reye_pose=zero_pose,\n",
    "                               left_hand_pose=param['pose_hand'][:, :45], right_hand_pose=param['pose_hand'][:, 45:],\n",
    "                               expression=param['face_expr'][:, :10], transl=param['trans']) # jaron: 这里加载smplx_model的目的是得到joints，然后对它选择+位移，使得角色是面朝z轴（处于原点）\n",
    "    print(smplx_output)          \n",
    "    vertices = smplx_output.vertices\n",
    "    joints = smplx_output.joints\n",
    "    joints = joints[:, joint_idx, :]\n",
    "    param['root_orient'], param['trans'] = face_z_transform(joints.cpu().numpy(), param['root_orient'], param['trans'])\n",
    "\n",
    "    pose_list = []\n",
    "    for k in ['root_orient', 'pose_body', 'pose_hand', 'pose_jaw', 'face_expr', 'face_shape', 'trans', 'betas']:\n",
    "        pose_list.append(param[k])\n",
    "    pose_list = torch.cat(pose_list, dim=-1).cpu().numpy()\n",
    "\n",
    "    return pose_list\n",
    "\n",
    "\n",
    "data = np.load(r\"D:\\jarondu\\Datasets\\motion_X_two\\AMASS\\BMLmovi\\BMLmovi\\Subject_1_F_MoSh\\Subject_1_F_1_stageii.npz\", allow_pickle=True)\n",
    "ex_fps = 30\n",
    "smplx_male_model_path = os.path.join(\"body_models/smplx\", \"SMPLX_MALE.npz\")\n",
    "smplx_female_model_path = os.path.join(\"body_models/smplx\", \"SMPLX_FEMALE.npz\")\n",
    "\n",
    "gender = data['gender'].item()\n",
    "\n",
    "if gender == 'male':\n",
    "    smplx_model = SMPLX(smplx_male_model_path, num_betas=10, use_pca=False, use_face_contour=True, batch_size=1).cuda()\n",
    "elif gender == 'female':\n",
    "    smplx_model = SMPLX(smplx_female_model_path, num_betas=10, use_pca=False, use_face_contour=True, batch_size=1).cuda()\n",
    "    \n",
    "pose = get_smplx_322(data, ex_fps)\n",
    "pose = process_pose(pose)\n",
    "\n",
    "pose = face_z_align(pose, smplx_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smplx_blender_addon加载.npz文件，.npz中不能缺少的{key: value}\n",
    "- 'gender'\n",
    "- 'mocap_frame_rate'\n",
    "- 'trans': (T,3)\n",
    "- 'pose': (T,165)\n",
    "- 'betas': 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gender', 'surface_model_type', 'mocap_frame_rate', 'mocap_time_length', 'markers_latent', 'latent_labels', 'markers_latent_vids', 'trans', 'poses', 'betas', 'num_betas', 'root_orient', 'pose_body', 'pose_hand', 'pose_jaw', 'pose_eye', 'markers', 'labels', 'markers_obs', 'labels_obs', 'markers_sim', 'marker_meta', 'num_markers'])\n",
      "(581, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(r\"D:\\jarondu\\Datasets\\motion_X_two\\AMASS\\BMLmovi\\BMLmovi\\Subject_1_F_MoSh\\Subject_1_F_1_stageii.npz\", allow_pickle=True)\n",
    "print(dict(data).keys())\n",
    "# print(dict(data))\n",
    "# print(data['poses'].shape) \n",
    "# print(data['root_orient'].shape) # equal to: data['poses'][..., 0:3]\n",
    "# print(data['pose_body'].shape) # equal to: data['poses'][..., 3:66]\n",
    "# print(data['pose_jaw'].shape) # equal to: data['poses'][..., 66:69]\n",
    "# print(data['pose_eye'].shape) # equal to: data['poses'][..., 69:75]\n",
    "# print(data['pose_hand'].shape) # equal to: data['poses'][..., 75:165]\n",
    "\n",
    "\n",
    "# joint_data = np.load(r\"D:\\jarondu\\Notes\\Text-to-Motion\\Evaluation\\【20240716】第一批打分\\MoMask_Original\\MoMask_Original\\000000\\repeat_0\\joint\\000000_repeat0_len196.npy\")\n",
    "# print(f\"joint_data.shape{joint_data.shape}\")\n",
    "# joint_body = joint_data.reshape(-1,66)[...,3:]\n",
    "# print(f\"joint_body.shape:{joint_body.shape}\")\n",
    "# joint_orient = joint_data.reshape(-1,66)[...,:3]\n",
    "# print(f\"joint_body.shape:{joint_body.shape}\")\n",
    "\n",
    "\n",
    "droped_key = ['markers_latent_vids', 'markers_latent', 'latent_labels', 'markers_obs', 'markers_sim', 'marker_meta', 'num_markers', 'markers_latent_vids', 'markers', \\\n",
    "              'surface_model_type', 'mocap_time_length', 'labels', 'labels_obs', \\\n",
    "              'num_betas', 'root_orient', 'pose_body', 'pose_hand', 'pose_jaw', 'pose_eye']\n",
    "modified_data = {}\n",
    "for key in list(data.keys()):\n",
    "    if key in droped_key:\n",
    "        continue\n",
    "    modified_data[key] = data[key]\n",
    "np.savez('./test.npz',**modified_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trans', 'gender', 'mocap_frame_rate', 'mocap_framerate', 'betas', 'dmpls', 'poses'])\n",
      "<class 'numpy.ndarray'>\n",
      "(1955, 156)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data1 = np.load('test.npz', allow_pickle=True)\n",
    "print(dict(data1).keys())\n",
    "print(type(data1['trans']))\n",
    "print(data1['poses'].shape)\n",
    "print(type(data1['betas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['trans', 'gender', 'mocap_framerate', 'betas', 'dmpls', 'poses'])\n",
      "(1955, 3)\n",
      "(1955, 156)\n",
      "(16,)\n",
      "120.0\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# data2 = np.load(r'C:\\Users\\jarondu\\Downloads\\ACCAD\\ACCAD\\s011\\walkdog_poses.npz', allow_pickle=True)\n",
    "# print(dict(data2).keys())\n",
    "# print(data2['trans'].shape)\n",
    "# print(data2['poses'].shape)\n",
    "# print(data2['betas'].shape)\n",
    "# print(data2['mocap_framerate'])\n",
    "# modified_data = {}\n",
    "# for key in list(data2.keys()):\n",
    "#     if key == \"mocap_framerate\":\n",
    "#         modified_data['mocap_frame_rate'] = data2[key]\n",
    "#     modified_data[key] = data2[key]\n",
    "# np.savez('./test.npz',**modified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vertices', 'joints', 'global_orient', 'betas', 'body_pose'])\n"
     ]
    }
   ],
   "source": [
    "data_smpl = np.load(r'./text_smpl.npz', allow_pickle=True)\n",
    "print(dict(data_smpl).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vertices', 'joints', 'global_orient', 'betas', 'body_pose'])\n",
      "(196, 3)\n",
      "(196, 10)\n",
      "(196, 63)\n",
      "hand_pose:(196, 90)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个smplx模型，然后往里面填参数\n",
    "from smplx import SMPLX\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def rotate(rotvec, rotation):\n",
    "    '''\n",
    "    input:\n",
    "        rotvec: 轴角表示的旋转\n",
    "        rotation: 需要旋转的旋转向量\n",
    "    return:\n",
    "        rotvec_res: 旋转后的轴角表示\n",
    "    '''\n",
    "\n",
    "    # 创建沿x轴旋转90度的Rotation对象\n",
    "    x_rotation_90 = R.from_rotvec(rotation)\n",
    "\n",
    "    # 将root_orient数组转换为Rotation对象数组\n",
    "    root_orient_rotations = R.from_rotvec(root_orient)\n",
    "\n",
    "    # 批量复合旋转\n",
    "    final_rotations = x_rotation_90 * root_orient_rotations\n",
    "\n",
    "    # 将复合后的旋转转换回轴角表示\n",
    "    rotvec_res = final_rotations.as_rotvec()\n",
    "\n",
    "    return rotvec_res\n",
    "\n",
    "smplx_male_model_path = os.path.join('./body_models/smplx', \"SMPLX_MALE.npz\")\n",
    "smplx_female_model_path = os.path.join('./body_models/smplx', \"SMPLX_FEMALE.npz\")\n",
    "gender = \"male\"\n",
    "if gender == 'male':\n",
    "    smplx_model = SMPLX(smplx_male_model_path, num_betas=10, use_pca=False, use_face_contour=True, batch_size=1).cuda()\n",
    "elif gender == 'female':\n",
    "    smplx_model = SMPLX(smplx_female_model_path, num_betas=10, use_pca=False, use_face_contour=True, batch_size=1).cuda()\n",
    "\n",
    "\n",
    "data_smpl = np.load(r'./text_smpl.npz', allow_pickle=True)\n",
    "print(dict(data_smpl).keys())\n",
    "print(data_smpl['global_orient'].shape)\n",
    "print(data_smpl['betas'].shape)\n",
    "print(data_smpl['body_pose'][...,:63].shape)\n",
    "\n",
    "batch_size = data_smpl['body_pose'].shape[0]\n",
    "root_orient = data_smpl['global_orient']\n",
    "body_pose = data_smpl['body_pose'][...,:63]\n",
    "jaw_pose = np.zeros((batch_size, 3))\n",
    "eye_pose = np.zeros((batch_size, 6))\n",
    "hand_pose = np.zeros((batch_size, 90))\n",
    "print(f\"hand_pose:{hand_pose.shape}\")\n",
    "\n",
    "# 需要施加的旋转向量\n",
    "x_rotation_90_rad = np.deg2rad(90)\n",
    "rotation = np.array([1, 0, 0]) * x_rotation_90_rad\n",
    "root_orient = rotate(root_orient, rotation)\n",
    "\n",
    "poses = np.concatenate([root_orient, body_pose, jaw_pose, eye_pose, hand_pose], axis=1)\n",
    "mocap_frame_rate = 30\n",
    "gender = 'male'\n",
    "# trans = torch.zeros((batch_size, 3)).float().numpy()\n",
    "trans = np.load('./temp.npy', allow_pickle=True)\n",
    "betas = torch.zeros((10)).float().numpy()\n",
    "\n",
    "paras = {\n",
    "    'poses': poses,\n",
    "    'gender': gender,\n",
    "    'mocap_frame_rate': mocap_frame_rate,\n",
    "    'trans': trans,\n",
    "    'betas': betas\n",
    "}\n",
    "\n",
    "np.savez('test_smplx.npz', **paras)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_motionx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
